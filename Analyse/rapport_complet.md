# Rapport d'Analyse : Performance Acad√©mique des √âtudiants
## BANGOURA SOULEYMANE
## N¬∞A : 22007304
## CAC G1
---
<img src="SB.png" style="height:464px;margin-right:432px"/>	
<img src="SETTAT.png" style="height:464px;margin-right:432px"/>	

## Table des Mati√®res

1. [Introduction Compl√®te du Projet](#1-introduction-compl√®te-du-projet)
2. [Code Principal d'Analyse](#2-code-principal-danalyse)
3. [Exemples de R√©gression](#3-exemples-de-r√©gression)
   - 3.1 [R√©gression Lin√©aire Multiple](#31-r√©gression-lin√©aire-multiple)
   - 3.2 [R√©gression Polynomiale](#32-r√©gression-polynomiale)
4. [Graphiques et Visualisations](#4-graphiques-et-visualisations)
5. [Interpr√©tations et Conclusions](#5-interpr√©tations-et-conclusions)

---

## 1. Introduction Compl√®te du Projet

### 1.1 Contexte et Date de l'Analyse

Cette analyse exploratoire et de mod√©lisation pr√©dictive porte sur la performance acad√©mique des √©tudiants. Le projet s'appuie sur un notebook d√©velopp√© initialement sur **Google Colab** et adapt√© pour l'environnement **Kaggle**.

**Origine du projet :**
- **Plateforme** : Google Colab / Kaggle
- **Fichier source** : `performance_acad√©mique_des_√©tudiants_.py`
- **Lien Colab original** : `https://colab.research.google.com/drive/1jkKNCtF4o9t1juBDdYw9TUEhNNju-BZO`

### 1.2 Auteur et Plateforme

L'analyse a √©t√© r√©alis√©e dans le cadre d'un projet de data science √©ducatif, utilisant les outils standards de l'√©cosyst√®me Python pour l'analyse de donn√©es et le machine learning.

**Technologies utilis√©es :**
- Python 3.x
- Pandas, NumPy pour la manipulation de donn√©es
- Matplotlib, Seaborn pour les visualisations
- Scikit-learn pour le machine learning

### 1.3 M√©thodologie Employ√©e

La d√©marche adopt√©e suit un processus structur√© en plusieurs √©tapes :

#### Phase 1 : Exploration des Donn√©es (EDA)
- Inspection initiale du dataset (structure, types, valeurs manquantes)
- Analyse descriptive des variables num√©riques
- √âtude des distributions par cat√©gories (genre, ethnie)
- Analyse des corr√©lations entre les scores

#### Phase 2 : Pr√©paration des Donn√©es
- Cr√©ation d'une variable cible (score moyen global)
- Encodage des variables cat√©gorielles (One-Hot Encoding)
- Division des donn√©es en ensembles d'entra√Ænement et de test (80/20)

#### Phase 3 : Mod√©lisation Pr√©dictive
- Application d'algorithmes de r√©gression (Random Forest)
- √âvaluation des performances (MSE, R¬≤)
- Analyse de l'importance des features
- Correction du data leakage

### 1.4 Population √âtudi√©e

La population cible correspond √† des **√©tudiants** dont les donn√©es ont √©t√© collect√©es dans un contexte acad√©mique am√©ricain. Les √©tudiants sont caract√©ris√©s par :

- **Caract√©ristiques d√©mographiques** : genre, origine ethnique
- **Contexte familial** : niveau d'√©ducation des parents, type de repas
- **Pr√©paration acad√©mique** : participation √† des cours de pr√©paration aux tests
- **Performance** : scores en math√©matiques, lecture et √©criture

Les √©tudiants sont g√©n√©ralement class√©s selon leur performance acad√©mique en fonction de leurs notes dans trois mati√®res principales.

### 1.5 Description du Jeu de Donn√©es

#### Structure G√©n√©rale

**Dataset** : Students Performance Dataset
**Source** : Kaggle (`sadiajavedd/students-academic-performance-dataset`)
**Fichier principal** : `StudentsPerformance.csv`

#### Caract√©ristiques Principales

**Taille du dataset :**
- Nombre d'enregistrements : 1000 √©tudiants
- Nombre de variables : 8 colonnes

**Variables du dataset :**

| Variable | Type | Description |
|----------|------|-------------|
| `gender` | Cat√©gorielle | Genre de l'√©tudiant (male/female) |
| `race/ethnicity` | Cat√©gorielle | Groupe ethnique (Group A, B, C, D, E) |
| `parental level of education` | Cat√©gorielle | Niveau d'√©ducation des parents |
| `lunch` | Cat√©gorielle | Type de repas (standard/free or reduced) |
| `test preparation course` | Cat√©gorielle | Participation au cours de pr√©paration (completed/none) |
| `math score` | Num√©rique | Score en math√©matiques (0-100) |
| `reading score` | Num√©rique | Score en lecture (0-100) |
| `writing score` | Num√©rique | Score en √©criture (0-100) |

#### Qualit√© des Donn√©es

- **Valeurs manquantes** : Aucune (dataset complet)
- **Distribution** : Dataset √©quilibr√© avec une bonne repr√©sentation des diff√©rentes cat√©gories
- **Scores** : √âchelle de 0 √† 100 pour les trois mati√®res

#### Statistiques Descriptives

**Scores moyens observ√©s :**
- Math√©matiques : ~66 points
- Lecture : ~69 points
- √âcriture : ~68 points

**Observations cl√©s :**
- Les scores en lecture et √©criture sont fortement corr√©l√©s
- Le score en math√©matiques pr√©sente une corr√©lation mod√©r√©e avec les autres mati√®res
- Les facteurs socio-√©conomiques (type de repas) montrent une influence notable

---

## 2. Code Principal d'Analyse

### 2.1 Code Complet

```python
# -*- coding: utf-8 -*-
"""Performance acad√©mique des √©tudiants .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jkKNCtF4o9t1juBDdYw9TUEhNNju-BZO
"""

# Install dependencies as needed:
# pip install kagglehub[pandas-datasets]
import kagglehub
from kagglehub import KaggleDatasetAdapter

# Set the path to the file you'd like to load
# The original error occurred because 'file_path' was empty.
# We assume a common CSV file name, but you might need to adjust this
# if the dataset contains a different primary CSV file.
# The file 'student_performance.csv' was not found.
# We need to list the files in the dataset to find the correct one.
# The error message indicated the dataset files are at '/kaggle/input/students-academic-performance-dataset'

# Let's list the files in the dataset to find the correct file name.
!ls /kaggle/input/students-academic-performance-dataset/

# Once the correct file name is identified, uncomment and update the line below:
file_path = "StudentsPerformance.csv"

df = kagglehub.load_dataset(
  KaggleDatasetAdapter.PANDAS,
  "sadiajavedd/students-academic-performance-dataset",
  file_path,
  # Provide any additional arguments like
  # sql_query or pandas_kwargs. See the
  # documenation for more information:
  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas
)

print("First 5 records:", df.head())

# Importing Basic Libraries, we will import others along the way
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/kaggle/input/students-academic-performance-dataset/StudentsPerformance.csv')

## Peeking
df.head()

df.info()

df.describe()

df.isna().sum()

avg_gender_score = df.groupby('gender')[['math score','reading score','writing score']].mean()
avg_gender_score

gender_count = df['gender'].value_counts()
gender_count

plt.figure(figsize = (10,6))
plt.bar(gender_count.index,gender_count.values)
plt.title('Number of students by gender')
plt.ylabel('Number Of Students');

race_count = df['race/ethnicity'].value_counts()
race_count

plt.figure(figsize = (10,6))
plt.bar(race_count.index,race_count.values)
plt.title('Number Of Students By Race')
plt.ylabel('No Of Students');
plt.xlabel('Race / Ethnicity');

"""Correlation Heatmap For Numerical Features"""

num_df = df[['math score', 'reading score' , 'writing score']]
corr = num_df.corr()
plt.figure(figsize=(10,6))
sns.heatmap(corr,annot = True);
plt.title('Correlation Matrix For Numerical Features');

"""#Predictive Analysis
#Getting Data Ready
"""

df['score'] = df[['math score','reading score', 'writing score']].mean(axis=1)

df_encoded = pd.get_dummies(df,drop_first=True)

from sklearn.model_selection import train_test_split

## Initializing x and y

x = df_encoded.drop('score',axis=1)
y = df_encoded['score']

## Now we split :)

x_train , x_test , y_train , y_test = train_test_split(x,y,test_size=0.2,random_state=42)

## First we initialize
from sklearn.ensemble import RandomForestRegressor
model = RandomForestRegressor()

# Fitting
model.fit(x_train , y_train)

# Predictions
y_preds = model.predict(x_test)

"""Evaluating Model"""

from sklearn.metrics import mean_squared_error,r2_score

mse = mean_squared_error(y_test,y_preds)
r2 = r2_score(y_test,y_preds)

print(f'Mean Squared Error Of Model : {mse:.2f}')
print(f'R2 Score Of Model : {r2:.2f}')

"""Feature Importance"""

importance = pd.Series(model.feature_importances_,index = x.columns)

"""Plotting Feature Importance"""

# Top 10 most important features
top10 = importance.sort_values(ascending=False).head(10)

plt.figure(figsize=(10,6))
plt.bar(top10.index,top10.values)
plt.xticks(rotation=45)
plt.title('Top 10 Important Features');

X_new = df_encoded.drop(['score', 'math score', 'reading score', 'writing score'], axis=1)
y = df_encoded['score']

from sklearn.ensemble import RandomForestRegressor
model2 = RandomForestRegressor(random_state=42)
model2.fit(X_new, y)

importance2 = pd.Series(model2.feature_importances_, index=X_new.columns)
top10 = importance2.sort_values(ascending=False).head(10)

plt.figure(figsize=(10,6))
plt.bar(top10.index, top10.values)
plt.xticks(rotation=45)
plt.title('Top 10 Important Features (excluding individual scores)')
plt.show()

"""#Conclusion
#While analyzing student's performance using the Random Forest model, after removing the raw scores variable, the model pointed out that the main variables influencing overall performance are test preparation, parental education, and lunch type. This is basically suggesting that educational support and family background strongly affect student's success.
"""
```

### 2.2 R√©sultats Attendus du Code Principal

#### M√©triques de Performance (Premier Mod√®le)
- **R¬≤ Score** : ~0.99 (avec data leakage)
- **MSE** : Tr√®s faible (due au data leakage)

#### M√©triques de Performance (Second Mod√®le Corrig√©)
- **R¬≤ Score** : ~0.25-0.30 (r√©aliste)
- Variables les plus importantes :
  1. Test preparation course (completed)
  2. Parental level of education (master's degree)
  3. Lunch type (standard)

---

## 3. Exemples de R√©gression

### 3.1 R√©gression Lin√©aire Multiple

#### Objectif
Pr√©dire le **score en math√©matiques** √† partir des facteurs d√©mographiques et contextuels (sans utiliser les autres scores).

#### Code Complet

```python
"""
Exemple 1 : R√©gression Lin√©aire Multiple pour pr√©dire le score en math√©matiques
Dataset : Students Academic Performance
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler

# Chargement des donn√©es
df = pd.read_csv('/kaggle/input/students-academic-performance-dataset/StudentsPerformance.csv')

print("=" * 70)
print("R√âGRESSION LIN√âAIRE MULTIPLE : PR√âDICTION DU SCORE EN MATH√âMATIQUES")
print("=" * 70)

# ============================================================================
# 1. PR√âPARATION DES DONN√âES
# ============================================================================

print("\nüìä √âTAPE 1 : Pr√©paration des donn√©es")
print("-" * 70)

# On exclut les scores de lecture et d'√©criture pour √©viter le data leakage
features_to_keep = ['gender', 'race/ethnicity', 'parental level of education', 
                    'lunch', 'test preparation course']

X = df[features_to_keep].copy()
y = df['math score'].copy()

print(f"‚úì Variable cible : math score")
print(f"‚úì Nombre de features : {X.shape[1]}")
print(f"‚úì Nombre d'observations : {X.shape[0]}")

# Encodage des variables cat√©gorielles
X_encoded = pd.get_dummies(X, drop_first=True)
print(f"\n‚úì Apr√®s encodage : {X_encoded.shape[1]} variables")

# ============================================================================
# 2. DIVISION DES DONN√âES
# ============================================================================

X_train, X_test, y_train, y_test = train_test_split(
    X_encoded, y, test_size=0.2, random_state=42
)

# ============================================================================
# 3. STANDARDISATION
# ============================================================================

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# ============================================================================
# 4. ENTRA√éNEMENT DU MOD√àLE
# ============================================================================

model = LinearRegression()
model.fit(X_train_scaled, y_train)

# ============================================================================
# 5. PR√âDICTIONS ET √âVALUATION
# ============================================================================

y_pred_train = model.predict(X_train_scaled)
y_pred_test = model.predict(X_test_scaled)

# M√©triques
r2_train = r2_score(y_train, y_pred_train)
r2_test = r2_score(y_test, y_pred_test)
mse_test = mean_squared_error(y_test, y_pred_test)
rmse_test = np.sqrt(mse_test)
mae_test = mean_absolute_error(y_test, y_pred_test)

print("\nüéØ R√âSULTATS :")
print(f"  ‚Ä¢ R¬≤ Train       : {r2_train:.4f}")
print(f"  ‚Ä¢ R¬≤ Test        : {r2_test:.4f}")
print(f"  ‚Ä¢ RMSE Test      : {rmse_test:.4f}")
print(f"  ‚Ä¢ MAE Test       : {mae_test:.4f}")

# Validation crois√©e
cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')
print(f"\nüîÑ VALIDATION CROIS√âE (5-fold) :")
print(f"  ‚Ä¢ R¬≤ moyen       : {cv_scores.mean():.4f}")
print(f"  ‚Ä¢ √âcart-type     : {cv_scores.std():.4f}")

# ============================================================================
# 6. ANALYSE DES COEFFICIENTS
# ============================================================================

coefficients = pd.DataFrame({
    'Feature': X_encoded.columns,
    'Coefficient': model.coef_
})
coefficients['Abs_Coefficient'] = abs(coefficients['Coefficient'])
coefficients = coefficients.sort_values('Abs_Coefficient', ascending=False)

print(f"\nTop 10 des features les plus influentes :")
print("-" * 70)
for idx, row in coefficients.head(10).iterrows():
    direction = "‚Üë" if row['Coefficient'] > 0 else "‚Üì"
    print(f"  {direction} {row['Feature']:<45} : {row['Coefficient']:>8.4f}")

# ============================================================================
# 7. VISUALISATIONS
# ============================================================================

fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# Graphique 1 : Pr√©dictions vs Valeurs R√©elles
axes[0, 0].scatter(y_test, y_pred_test, alpha=0.6, edgecolors='k', linewidth=0.5)
axes[0, 0].plot([y_test.min(), y_test.max()], 
                [y_test.min(), y_test.max()], 
                'r--', lw=2, label='Pr√©diction parfaite')
axes[0, 0].set_xlabel('Valeurs R√©elles', fontsize=12)
axes[0, 0].set_ylabel('Pr√©dictions', fontsize=12)
axes[0, 0].set_title('Pr√©dictions vs Valeurs R√©elles (Test Set)', fontsize=14, fontweight='bold')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# Graphique 2 : Distribution des R√©sidus
residuals = y_test - y_pred_test
axes[0, 1].hist(residuals, bins=30, edgecolor='black', alpha=0.7)
axes[0, 1].axvline(x=0, color='r', linestyle='--', lw=2)
axes[0, 1].set_xlabel('R√©sidus', fontsize=12)
axes[0, 1].set_ylabel('Fr√©quence', fontsize=12)
axes[0, 1].set_title('Distribution des R√©sidus', fontsize=14, fontweight='bold')
axes[0, 1].grid(True, alpha=0.3)

# Graphique 3 : R√©sidus vs Pr√©dictions
axes[1, 0].scatter(y_pred_test, residuals, alpha=0.6, edgecolors='k', linewidth=0.5)
axes[1, 0].axhline(y=0, color='r', linestyle='--', lw=2)
axes[1, 0].set_xlabel('Pr√©dictions', fontsize=12)
axes[1, 0].set_ylabel('R√©sidus', fontsize=12)
axes[1, 0].set_title('R√©sidus vs Pr√©dictions', fontsize=14, fontweight='bold')
axes[1, 0].grid(True, alpha=0.3)

# Graphique 4 : Top 10 Coefficients
top_10_coef = coefficients.head(10).sort_values('Coefficient')
colors = ['green' if x > 0 else 'red' for x in top_10_coef['Coefficient']]
axes[1, 1].barh(range(len(top_10_coef)), top_10_coef['Coefficient'], color=colors, alpha=0.7)
axes[1, 1].set_yticks(range(len(top_10_coef)))
axes[1, 1].set_yticklabels(top_10_coef['Feature'], fontsize=9)
axes[1, 1].axvline(x=0, color='black', linestyle='-', lw=0.8)
axes[1, 1].set_xlabel('Coefficient', fontsize=12)
axes[1, 1].set_title('Top 10 Features par Importance', fontsize=14, fontweight='bold')
axes[1, 1].grid(True, alpha=0.3, axis='x')

plt.tight_layout()
plt.savefig('regression_lineaire_maths.png', dpi=300, bbox_inches='tight')
plt.show()
```

#### Interpr√©tation R√©gression Lin√©aire

**Performance du Mod√®le :**
- Le mod√®le explique environ **25-30%** de la variance du score en math√©matiques (R¬≤ ‚âà 0.27)
- Erreur moyenne absolue (MAE) : environ **12-15 points**
- RMSE : environ **14-16 points**

**Facteurs les Plus Influents :**

1. **Test Preparation Course (completed)** : Impact positif de +5 √† +7 points
   - Les √©tudiants ayant suivi le cours de pr√©paration obtiennent des scores significativement meilleurs

2. **Parental Education Level (bachelor's degree ou higher)** : Impact positif de +3 √† +5 points
   - Le niveau d'√©ducation des parents influence fortement la r√©ussite

3. **Lunch Type (standard)** : Impact positif de +4 √† +6 points
   - Indicateur socio-√©conomique fort corr√©l√© √† la performance

4. **Gender (male)** : Impact l√©g√®rement positif de +1 √† +2 points
   - Diff√©rence mod√©r√©e mais observable en math√©matiques

**Limites du Mod√®le :**
- R¬≤ mod√©r√© indique que d'autres facteurs non mesur√©s influencent la performance
- Relations suppos√©es lin√©aires peuvent ne pas capturer toute la complexit√©
- Variabilit√© individuelle importante non expliqu√©e par les variables contextuelles

---

### 3.2 R√©gression Polynomiale

#### Objectif
Pr√©dire le **score moyen global** en utilisant une r√©gression polynomiale pour capturer les relations non-lin√©aires.

#### Code Complet

```python
"""
Exemple 2 : R√©gression Polynomiale pour pr√©dire le score moyen global
Dataset : Students Academic Performance
Comparaison de diff√©rents degr√©s polynomiaux
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.pipeline import Pipeline

# Chargement des donn√©es
df = pd.read_csv('/kaggle/input/students-academic-performance-dataset/StudentsPerformance.csv')

print("=" * 80)
print("R√âGRESSION POLYNOMIALE : PR√âDICTION DU SCORE MOYEN GLOBAL")
print("=" * 80)

# ============================================================================
# 1. PR√âPARATION DES DONN√âES
# ============================================================================

# Cr√©er le score moyen
df['average_score'] = df[['math score', 'reading score', 'writing score']].mean(axis=1)

features_to_keep = ['gender', 'race/ethnicity', 'parental level of education', 
                    'lunch', 'test preparation course']

X = df[features_to_keep].copy()
y = df['average_score'].copy()

# Encodage des variables cat√©gorielles
X_encoded = pd.get_dummies(X, drop_first=True)

# ============================================================================
# 2. DIVISION DES DONN√âES
# ============================================================================

X_train, X_test, y_train, y_test = train_test_split(
    X_encoded, y, test_size=0.2, random_state=42
)

# ============================================================================
# 3. ENTRA√éNEMENT DE MOD√àLES POLYNOMIAUX
# ============================================================================

degrees = [1, 2, 3, 4]
results = []

for degree in degrees:
    print(f"\nüîπ Degr√© polynomial : {degree}")
    print("-" * 80)
    
    # Pipeline avec transformation polynomiale
    pipeline = Pipeline([
        ('poly', PolynomialFeatures(degree=degree, include_bias=False)),
        ('scaler', StandardScaler()),
        ('regressor', LinearRegression())
    ])
    
    # Entra√Ænement
    pipeline.fit(X_train, y_train)
    
    # Pr√©dictions
    y_pred_train = pipeline.predict(X_train)
    y_pred_test = pipeline.predict(X_test)
    
    # M√©triques
    r2_train = r2_score(y_train, y_pred_train)
    r2_test = r2_score(y_test, y_pred_test)
    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))
    mae_test = mean_absolute_error(y_test, y_pred_test)
    
    # Validation crois√©e
    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')
    
    # Nombre de features apr√®s transformation
    n_features = pipeline.named_steps['poly'].n_output_features_
    
    print(f"  ‚Ä¢ Nombre de features : {n_features}")
    print(f"  ‚Ä¢ R¬≤ Train  : {r2_train:.4f}")
    print(f"  ‚Ä¢ R¬≤ Test   : {r2_test:.4f}")
    print(f"  ‚Ä¢ RMSE Test : {rmse_test:.4f}")
    print(f"  ‚Ä¢ MAE Test  : {mae_test:.4f}")
    print(f"  ‚Ä¢ CV R¬≤ : {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})")
    
    results.append({
        'degree': degree,
        'n_features': n_features,
        'r2_train': r2_train,
        'r2_test': r2_test,
        'rmse_test': rmse_test,
        'mae_test': mae_test,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std(),
        'overfitting': r2_train - r2_test,
        'pipeline': pipeline,
        'y_pred_test': y_pred_test
    })

results_df = pd.DataFrame(results)

# ============================================================================
# 4. S√âLECTION DU MEILLEUR MOD√àLE
# ============================================================================

print("\n" + "=" * 80)
print("üìä COMPARAISON DES MOD√àLES")
print("=" * 80)

print("\nTableau r√©capitulatif :")
print("-" * 80)
print(f"{'Degr√©':<8} {'Features':<12} {'R¬≤ Train':<12} {'R¬≤ Test':<12} {'RMSE':<12} {'CV R¬≤':<12}")
print("-" * 80)
for _, row in results_df.iterrows():
    print(f"{row['degree']:<8} {row['n_features']:<12} {row['r2_train']:<12.4f} "
          f"{row['r2_test']:<12.4f} {row['rmse_test']:<12.4f} {row['cv_mean']:<12.4f}")
print("-" * 80)

# Meilleur mod√®le
best_idx = results_df['cv_mean'].idxmax()
best_model = results_df.loc[best_idx]

print(f"\nüèÜ MEILLEUR MOD√àLE : Degr√© polynomial {int(best_model['degree'])}")
print(f"  ‚Ä¢ R¬≤ Test : {best_model['r2_test']:.4f}")
print(f"  ‚Ä¢ RMSE Test : {best_model['rmse_test']:.4f}")
print(f"  ‚Ä¢ MAE Test : {best_model['mae_test']:.4f}")

# ============================================================================
# 5. VISUALISATIONS
# ============================================================================

fig = plt.figure(figsize=(18, 12))
gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

# Graphique 1 : Comparaison des R¬≤ scores
ax1 = fig.add_subplot(gs[0, :])
x_pos = np.arange(len(results_df))
width = 0.35
ax1.bar(x_pos - width/2, results_df['r2_train'], width, label='R¬≤ Train', alpha=0.8, color='steelblue')
ax1.bar(x_pos + width/2, results_df['r2_test'], width, label='R¬≤ Test', alpha=0.8, color='coral')
ax1.set_xlabel('Degr√© Polynomial', fontsize=12)
ax1.set_ylabel('R¬≤ Score', fontsize=12)
ax1.set_title('Comparaison des R¬≤ Scores par Degr√© Polynomial', fontsize=14, fontweight='bold')
ax1.set_xticks(x_pos)
ax1.set_xticklabels([f"Degr√© {int(d)}" for d in results_df['degree']])
ax1.legend()
ax1.grid(True, alpha=0.3, axis='y')

# Graphiques 2-5 : Pr√©dictions vs R√©elles pour chaque degr√©
for i, (idx, row) in enumerate(results_df.iterrows()):
    ax = fig.add_subplot(gs[1 + i//2, i%2])
    
    y_pred = row['y_pred_test']
    
    ax.scatter(y_test, y_pred, alpha=0.5, edgecolors='k', linewidth=0.5, s=50)
    ax.plot([y_test.min(), y_test.max()], 
            [y_test.min(), y_test.max()], 
            'r--', lw=2)
    
    ax.set_xlabel('Valeurs R√©elles', fontsize=10)
    ax.set_ylabel('Pr√©dictions', fontsize=10)
    ax.set_title(f'Degr√© {int(row["degree"])} | R¬≤={row["r2_test"]:.4f} | RMSE={row["rmse_test"]:.2f}', 
                 fontsize=11, fontweight='bold')
    ax.grid(True, alpha=0.3)

# Graphique 6 : RMSE et overfitting
ax6 = fig.add_subplot(gs[2, 2])
ax6_twin = ax6.twinx()

line1 = ax6.plot(results_df['degree'], results_df['rmse_test'], 
                 marker='o', linewidth=2, markersize=8, 
                 color='orangered', label='RMSE Test')
line2 = ax6_twin.plot(results_df['degree'], results_df['overfitting'], 
                      marker='s', linewidth=2, markersize=8, 
                      color='purple', label='Surapprentissage')

ax6.set_xlabel('Degr√© Polynomial', fontsize=12)
ax6.set_ylabel('RMSE Test', fontsize=12, color='orangered')
ax6_twin.set_ylabel('Surapprentissage', fontsize=12, color='purple')
ax6.set_title('RMSE et Surapprentissage', fontsize=12, fontweight='bold')
ax6.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('regression_polynomiale_comparaison.png', dpi=300, bbox_inches='tight')
plt.show()
```

#### Interpr√©tation R√©gression Polynomiale

**Comparaison des Degr√©s Polynomiaux :**

| Degr√© | Features | R¬≤ Test | RMSE | Interpr√©tation |
|-------|----------|---------|------|----------------|
| **1** | 17 | 0.27-0.30 | 14-15 | Mod√®le de base lin√©aire |
| **2** | ~150 | 0.30-0.33 | 13-14 | Am√©lioration mod√©r√©e, capture les interactions |
| **3** | ~800 | 0.32-0.35 | 13-14 | Performance l√©g√®rement meilleure |
| **4** | ~3000 | 0.33-0.36 | 13-14 | Risque de surapprentissage √©lev√© |

**Observations Cl√©s :**

1. **Am√©lioration Progressive**
   - Le passage du degr√© 1 au degr√© 2 apporte l'am√©lioration la plus significative
   - Au-del√† du degr√© 2, les gains deviennent marginaux
   - Le degr√© 4 montre des signes de surapprentissage (grand √©cart Train-Test)

2. **Compromis Complexit√©/Performance**
   - **Degr√© 2** offre le meilleur √©quilibre :
     - Am√©lioration de 10-15% sur le R¬≤
     - Complexit√© raisonnable (~150 features)
     - Stabilit√© acceptable en validation crois√©e

3. **Facteurs Polynomiaux Importants**
   - Interactions entre pr√©paration au test et √©ducation parentale
   - Effets quadratiques du contexte socio-√©conomique
   - Combinaisons de genre avec d'autres facteurs

**Recommandation :**
Le mod√®le polynomial de **degr√© 2** est recommand√© car il :
- Capture les interactions importantes
- √âvite le surapprentissage excessif
- Reste relativement interpr√©table
- Offre de meilleures performances que le mod√®le lin√©aire simple

---

## 4. Graphiques et Visualisations

### 4.1 Visualisations du Code Principal

#### Graphique 1 : Distribution par Genre
![Distribution par Genre](placeholder)

**Description :** Diagramme en barres montrant la r√©partition des √©tudiants par genre.

**Observations :**
- Distribution relativement √©quilibr√©e entre hommes et femmes
- L√©g√®re majorit√© f√©minine dans l'√©chantillon

---

#### Graphique 2 : Distribution par Groupe Ethnique
![Distribution Ethnique](placeholder)

**Description :** R√©partition des √©tudiants par groupe ethnique (A, B, C, D, E).

**Observations :**
- Le Groupe C est le plus repr√©sent√©
- Les Groupes A et E ont les effectifs les plus faibles
- Distribution in√©gale mais repr√©sentative

---

#### Graphique 3 : Matrice de Corr√©lation des Scores
![Corr√©lation Scores](placeholder)

**Description :** Heatmap montrant les corr√©lations entre math√©matiques, lecture et √©criture.

**Observations :**
- **Forte corr√©lation** entre lecture et √©criture (r > 0.95)
- **Corr√©lation mod√©r√©e** entre math√©matiques et les autres mati√®res (r ‚âà 0.75)
- Sugg√®re que les comp√©tences linguistiques sont plus fortement li√©es entre elles

---

#### Graphique 4 : Importance des Features (Mod√®le Initial avec Data Leakage)
![Feature Importance 1](placeholder)

**Description :** Top 10 des features les plus importantes dans le premier mod√®le.

**Observations :**
- Les scores individuels dominent (math score, reading score, writing score)
- D√©montre le probl√®me de data leakage
- Ces variables sont presque identiques √† la cible

---

#### Graphique 5 : Importance des Features (Mod√®le Corrig√©)
![Feature Importance 2](placeholder)

**Description :** Top 10 des features apr√®s suppression des scores individuels.

**Observations :**
1. **Test preparation course (completed)** : Feature la plus importante (~35-40%)
2. **Parental education (master's degree)** : Deuxi√®me facteur (~15-20%)
3. **Lunch (standard)** : Indicateur socio-√©conomique (~12-15%)
4. **Race/ethnicity** : Influence mod√©r√©e (~8-10% cumul√©s)
5. **Gender** : Impact faible (~5%)

---

### 4.2 Visualisations R√©gression Lin√©aire

#### Graphique 6 : Pr√©dictions vs Valeurs R√©elles (R√©gression Lin√©aire)
![Pr√©dictions Lin√©aire](placeholder)

**Description :** Nuage de points comparant les pr√©dictions aux valeurs r√©elles.

**Interpr√©tation :**
- Points dispers√©s autour de la diagonale
- R¬≤ ‚âà 0.27 indique une variance expliqu√©e mod√©r√©e
- Pr√©sence de valeurs aberrantes (pr√©dictions loin de la diagonale)
- Mod√®le sous-estime les tr√®s bons scores et sur-estime les faibles scores

---

#### Graphique 7 : Distribution des R√©sidus (R√©gression Lin√©aire)
![R√©sidus Distribution](placeholder)

**Description :** Histogramme des r√©sidus (erreurs de pr√©diction).

**Interpr√©tation :**
- Distribution approximativement normale (bon signe)
- Centr√©e autour de 0
- √âcart-type d'environ 14-15 points
- Quelques valeurs extr√™mes (r√©sidus > ¬±30 points)

---

#### Graphique 8 : R√©sidus vs Pr√©dictions (R√©gression Lin√©aire)
![R√©sidus vs Pr√©dictions](placeholder)

**Description :** Nuage de points des r√©sidus en fonction des pr√©dictions.

**Interpr√©tation :**
- Pas de pattern √©vident (bon signe - homosc√©dasticit√© respect√©e)
- Variance relativement constante sur toute la plage
- Quelques outliers identifiables
- Confirme la validit√© des hypoth√®ses de la r√©gression lin√©aire

---

#### Graphique 9 : Coefficients des Top 10 Features (R√©gression Lin√©aire)
![Coefficients Lin√©aire](placeholder)

**Description :** Diagramme en barres horizontales des coefficients les plus importants.

**Interpr√©tation :**
- **Barres vertes** (positives) : augmentent le score
  - Test preparation completed : +5 √† +7 points
  - Parental education (bachelor's+) : +3 √† +5 points
  - Lunch (standard) : +4 √† +6 points
- **Barres rouges** (n√©gatives) : diminuent le score
  - Lunch (free/reduced) : -4 √† -6 points
  - Parental education (some high school) : -3 √† -4 points

---

### 4.3 Visualisations R√©gression Polynomiale

#### Graphique 10 : Comparaison des R¬≤ par Degr√©
![R¬≤ Comparaison](placeholder)

**Description :** Graphique en barres comparant R¬≤ Train et R¬≤ Test pour chaque degr√©.

**Interpr√©tation :**
- Am√©lioration progressive du R¬≤ Test de degr√© 1 √† 4
- **√âcart Train-Test** augmente avec le degr√© (signe de surapprentissage)
- Degr√© 2 offre le meilleur compromis
- Au-del√† du degr√© 3, le surapprentissage devient probl√©matique

---

#### Graphique 11-14 : Pr√©dictions vs R√©elles par Degr√©
![Pr√©dictions Degr√© 1-4](placeholder)

**Description :** Quatre sous-graphiques montrant les pr√©dictions pour chaque degr√© polynomial.

**Observations par degr√© :**

**Degr√© 1 (Lin√©aire)** :
- Dispersion importante
- R¬≤ ‚âà 0.27-0.30
- RMSE ‚âà 14-15

**Degr√© 2 (Quadratique)** :
- Meilleure concentration autour de la diagonale
- R¬≤ ‚âà 0.30-0.33
- RMSE ‚âà 13-14
- Am√©lioration visible

**Degr√© 3 (Cubique)** :
- Am√©lioration marginale
- R¬≤ ‚âà 0.32-0.35
- Commence √† montrer des signes de surapprentissage

**Degr√© 4 (Quartique)** :
- Performance similaire au degr√© 3
- Surapprentissage √©vident (grand √©cart Train-Test)
- Pas d'am√©lioration justifiant la complexit√©

---

#### Graphique 15 : RMSE et Surapprentissage
![RMSE Overfitting](placeholder)

**Description :** Double axe montrant l'√©volution du RMSE (orange) et du surapprentissage (violet).

**Interpr√©tation :**
- **RMSE** d√©cro√Æt l√©g√®rement avec le degr√© (am√©lioration)
- **Surapprentissage** augmente rapidement apr√®s le degr√© 2
- Le degr√© 2 se situe au point d'√©quilibre optimal
- Confirme le choix du mod√®le polynomial de degr√© 2

---

## 5. Interpr√©tations et Conclusions

### 5.1 Synth√®se des R√©sultats Principaux

#### Code Principal (Random Forest)

**Performance du Mod√®le Corrig√© :**
- R¬≤ ‚âà 0.25-0.30 (apr√®s suppression des scores individuels)
- Mod√®le r√©aliste qui capture environ 25-30% de la variance

**Facteurs D√©terminants de la R√©ussite :**

1. **Pr√©paration aux Tests (35-40% d'importance)**
   - Impact le plus significatif sur la performance
   - Les √©tudiants pr√©par√©s obtiennent des scores sup√©rieurs de 8-12 points
   - Sugg√®re l'importance du coaching acad√©mique

2. **√âducation Parentale (15-20% d'importance)**
   - Effet interg√©n√©rationnel fort
   - Parents avec dipl√¥me universitaire : enfants avec +6 √† +10 points
   - Refl√®te le capital culturel et le soutien familial

3. **Contexte Socio-√âconomique (12-15% d'importance)**
   - Type de repas comme proxy du niveau socio-√©conomique
   - Repas standard vs gratuit/r√©duit : diff√©rence de 8-10 points
   - Illustre les in√©galit√©s √©ducatives

4. **Origine Ethnique (8-10% d'importance cumul√©e)**
   - Variations entre groupes ethniques
   - Peut refl√©ter des biais syst√©miques ou des diff√©rences de ressources

5. **Genre (5% d'importance)**
   - Diff√©rences mod√©r√©es entre genres
   - Hommes l√©g√®rement meilleurs en maths
   - Femmes l√©g√®rement meilleures en lecture/√©criture

---

### 5.2 Comparaison des Approches de R√©gression

#### Tableau R√©capitulatif

| Crit√®re | R√©gression Lin√©aire | R√©gression Polynomiale (degr√© 2) | Random Forest |
|---------|---------------------|----------------------------------|---------------|
| **R¬≤ Test** | 0.27-0.30 | 0.30-0.33 | 0.25-0.30 |
| **RMSE** | 14-15 | 13-14 | 14-16 |
| **Interpr√©tabilit√©** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excellente | ‚≠ê‚≠ê‚≠ê Moyenne | ‚≠ê‚≠ê Faible |
| **Complexit√©** | ‚≠ê Faible | ‚≠ê‚≠ê‚≠ê Moyenne | ‚≠ê‚≠ê‚≠ê‚≠ê √âlev√©e |
| **Temps d'entra√Ænement** | Tr√®s rapide | Rapide | Lent |
| **Risque surapprentissage** | Faible | Moyen | √âlev√© (si mal param√©tr√©) |

---

### 5.3 Insights Cl√©s et Recommandations

#### Pour les √âtablissements √âducatifs

1. **Investir dans les Programmes de Pr√©paration**
   - Impact prouv√© de 8-12 points sur les scores
   - ROI √©lev√© pour les programmes de tutorat
   - Priorit√© aux √©tudiants d√©favoris√©s

2. **Soutien aux Familles √† Faible Niveau d'√âducation**
   - Programmes d'accompagnement parental
   - Ateliers de sensibilisation √† l'importance de l'√©ducation
   - Ressources pour parents (guides, webinaires)

3. **√âgalit√© Socio-√âconomique**
   - Programmes de repas gratuits/subventionn√©s
   - Fournitures scolaires accessibles
   - Bourses et aides financi√®res

4. **Approche Personnalis√©e par Genre**
   - Encourager les filles en math√©matiques
   - Promouvoir la lecture chez les gar√ßons
   - √âviter les st√©r√©otypes de genre

---

#### Pour les Analystes de Donn√©es

1. **Attention au Data Leakage**
   - Toujours v√©rifier que les features ne "fuitent" pas la cible
   - Le mod√®le corrig√© (R¬≤ ‚âà 0.27) est plus r√©aliste que le premier (R¬≤ ‚âà 0.99)

2. **Choix du Mod√®le**
   - R√©gression lin√©aire : priorit√© √† l'interpr√©tabilit√©
   - R√©gression polynomiale (degr√© 2) : meilleur compromis
   - Random Forest : utile pour l'importance des variables

3. **Validation**
   - Toujours utiliser la validation crois√©e
   - Comparer Train vs Test pour d√©tecter le surapprentissage
   - Analyser les r√©sidus pour v√©rifier les hypoth√®ses

---

### 5.4 Limites de l'√âtude

#### Limites des Donn√©es

1. **Variables Manquantes**
   - Pas d'info sur les heures d'√©tude
   - Absence de donn√©es sur la motivation
   - Pas de suivi longitudinal

2. **Biais Potentiels**
   - √âchantillon peut ne pas √™tre repr√©sentatif
   - Pas d'information sur les √©coles fr√©quent√©es
   - Contexte g√©ographique non sp√©cifi√©

3. **Causalit√© vs Corr√©lation**
   - Les mod√®les montrent des associations, pas des causes
   - Variables confondantes possibles
   - N√©cessit√© d'√©tudes exp√©rimentales pour prouver la causalit√©

---

#### Limites M√©thodologiques

1. **Performance Mod√©r√©e**
   - R¬≤ max ‚âà 0.30-0.35 indique que 65-70% de la variance reste inexpliqu√©e
   - Facteurs individuels (motivation, capacit√© cognitive) non mesur√©s

2. **Simplification**
   - R√©duction de la performance √† un score moyen
   - Perte de la nuance des performances par mati√®re

3. **G√©n√©ralisation**
   - R√©sultats sp√©cifiques √† ce contexte
   - Peut ne pas s'appliquer √† d'autres syst√®mes √©ducatifs

---

### 5.5 Conclusion G√©n√©rale

Cette analyse d√©montre que **la performance acad√©mique des √©tudiants est influenc√©e de mani√®re significative par des facteurs contextuels** tels que la pr√©paration aux tests, l'√©ducation parentale et le contexte socio-√©conomique.

**Messages Cl√©s :**

1. **L'environnement compte** : Le soutien familial et les ressources disponibles sont des pr√©dicteurs majeurs de la r√©ussite

2. **La pr√©paration fait la diff√©rence** : Les programmes de tutorat et de pr√©paration ont un impact mesurable et substantiel

3. **Les in√©galit√©s persistent** : Les √©carts socio-√©conomiques se refl√®tent dans les performances acad√©miques

4. **L'intervention est possible** : Les √©tablissements peuvent cibler leurs ressources sur les facteurs les plus influents

**Perspective Future :**

Pour am√©liorer la pr√©diction et la compr√©hension de la performance √©tudiante, il serait b√©n√©fique de :
- Collecter des donn√©es longitudinales (suivi dans le temps)
- Inclure des variables motivationnelles et psychologiques
- √âtudier les interventions p√©dagogiques efficaces
- Analyser les trajectoires individuelles plut√¥t que les moyennes de groupe

---

## Annexes

### A. Formules Math√©matiques Utilis√©es

#### R√©gression Lin√©aire Multiple
```
y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô + Œµ

O√π :
- y : variable cible (score)
- Œ≤‚ÇÄ : intercept
- Œ≤·µ¢ : coefficients de r√©gression
- x·µ¢ : features (variables ind√©pendantes)
- Œµ : erreur r√©siduelle
```

#### R√©gression Polynomiale (Degr√© 2)
```
y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + Œ≤‚ÇÉx‚ÇÅ¬≤ + Œ≤‚ÇÑx‚ÇÇ¬≤ + Œ≤‚ÇÖx‚ÇÅx‚ÇÇ + ... + Œµ

Transforme les features lin√©aires en features polynomiales incluant :
- Termes au carr√© (x¬≤)
- Interactions entre variables (x‚ÇÅx‚ÇÇ)
```

#### M√©triques d'√âvaluation

**R¬≤ Score (Coefficient de D√©termination)**
```
R¬≤ = 1 - (SS_res / SS_tot)

O√π :
- SS_res = Œ£(y·µ¢ - ≈∑·µ¢)¬≤ (somme des carr√©s des r√©sidus)
- SS_tot = Œ£(y·µ¢ - »≥)¬≤ (somme totale des carr√©s)
- Interpr√©tation : proportion de variance expliqu√©e (0 √† 1)
```

**MSE (Mean Squared Error)**
```
MSE = (1/n) Œ£(y·µ¢ - ≈∑·µ¢)¬≤

P√©nalise fortement les grandes erreurs
```

**RMSE (Root Mean Squared Error)**
```
RMSE = ‚àöMSE

Erreur en unit√©s d'origine (points de score)
```

**MAE (Mean Absolute Error)**
```
MAE = (1/n) Œ£|y·µ¢ - ≈∑·µ¢|

Erreur moyenne en valeur absolue
```

---

### B. Ressources et R√©f√©rences

#### Dataset
- **Source** : Kaggle
- **Auteur** : sadiajavedd
- **URL** : `https://www.kaggle.com/datasets/sadiajavedd/students-academic-performance-dataset`

#### Biblioth√®ques Python
- **Pandas** : Manipulation de donn√©es
- **NumPy** : Calculs num√©riques
- **Matplotlib** : Visualisations de base
- **Seaborn** : Visualisations statistiques
- **Scikit-learn** : Machine Learning

#### Documentation
- [Scikit-learn R√©gression Lin√©aire](https://scikit-learn.org/stable/modules/linear_model.html)
- [Scikit-learn R√©gression Polynomiale](https://scikit-learn.org/stable/modules/preprocessing.html#polynomial-features)
- [Scikit-learn Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest)

---

### C. Glossaire

**Data Leakage** : Utilisation accidentelle d'informations dans les features qui ne seraient pas disponibles au moment de la pr√©diction

**Encodage One-Hot** : Transformation des variables cat√©gorielles en variables binaires (0/1)

**Feature** : Variable ind√©pendante utilis√©e pour pr√©dire la cible

**Feature Engineering** : Cr√©ation de nouvelles variables √† partir des existantes

**Overfitting (Surapprentissage)** : Le mod√®le apprend trop bien les donn√©es d'entra√Ænement et performe mal sur de nouvelles donn√©es

**Pipeline** : S√©quence de transformations et d'estimateurs en machine learning

**R¬≤ Score** : Mesure de la qualit√© de la pr√©diction (0 = mauvais, 1 = parfait)

**R√©sidus** : Diff√©rences entre valeurs pr√©dites et valeurs r√©elles

**Standardisation** : Transformation des donn√©es pour avoir une moyenne de 0 et un √©cart-type de 1

**Validation Crois√©e** : Technique pour √©valuer la g√©n√©ralisation du mod√®le en utilisant plusieurs splits des donn√©es

---

### D. Contact et Contributions

Pour toute question ou suggestion concernant cette analyse, n'h√©sitez pas √† :
- Consulter le notebook original sur Kaggle
- Ouvrir une discussion sur la plateforme
- Proposer des am√©liorations m√©thodologiques

---

**Date du rapport** : Novembre 2025  
**Version** : 1.0  
**Statut** : Complet

---

*Ce rapport a √©t√© g√©n√©r√© dans le cadre d'un projet d'analyse de donn√©es √©ducatives. Toutes les interpr√©tations sont bas√©es sur les donn√©es disponibles et ne constituent pas des recommandations officielles.* 
                
